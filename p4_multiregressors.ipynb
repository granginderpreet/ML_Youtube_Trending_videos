{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2255e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb978d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import datetime\n",
    "\n",
    "db_password = \"postgres\"\n",
    "db_user = \"postgres\"\n",
    "db_name = \"Youtube P3\"\n",
    "endpoint = 'youtube.cb1bticre0py.us-east-1.rds.amazonaws.com'\n",
    "\n",
    "connection_string = f\"postgresql://{db_user}:{db_password}@{endpoint}:5432/{db_name}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "og_data = pd.read_sql('SELECT * FROM final_unique;', con = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25d22717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start here if you need to re-run instead of pulling from postgres in above cell\n",
    "\n",
    "final_unique = og_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b292917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id      111492\n",
      "trend_days    111492\n",
      "dtype: int64\n",
      "video_id      241112\n",
      "trend_days    241112\n",
      "dtype: int64\n",
      "video_id      0.4624\n",
      "trend_days    0.4624\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## chose target_days for classification model\n",
    "\n",
    "target_df = pd.DataFrame(final_unique[['video_id', 'trend_days']])\n",
    "\n",
    "target_days = 4   #     <---- pick your target days here\n",
    "\n",
    "# prints statement below\n",
    "print(target_df[target_df.trend_days > target_days].count())\n",
    "print(target_df[target_df.trend_days > 0].count())              \n",
    "print(round((target_df[target_df.trend_days > target_days].count()) / (target_df[target_df.trend_days > 0].count()),4))     \n",
    "\n",
    "#             ↓↓↓↓↓  videos above days threshold / total videos / % of dataset above days threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b9bf2415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111492, 34)\n",
      "(111492, 34)\n",
      "(222984, 35)\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['index', 'video_id', 'category', 'category_e', 'country',\n",
       "       'publish_date', 'trending_date', 'publish_to_trend', 'publish_day',\n",
       "       'publish_day_num', 'combined_trend_days', 'trend_days', 'views',\n",
       "       'pt_views', 'wt_views', 'pt_views_rate', 'wt_views_rate', 'likes',\n",
       "       'pt_likes', 'wt_likes', 'pt_likes_rate', 'wt_likes_rate', 'likes_ratio',\n",
       "       'dislikes', 'pt_dislikes', 'wt_dislikes', 'pt_dislikes_rate',\n",
       "       'wt_dislikes_rate', 'comments', 'pt_comments', 'wt_comments',\n",
       "       'pt_comments_rate', 'wt_comments_rate', 'comments_ratio', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataset with 50/50 > and < outcomes\n",
    "\n",
    "over_target = final_unique[final_unique.trend_days > target_days]\n",
    "under_target = final_unique[final_unique.trend_days <= target_days].sample(n=111492)  # <--- copy & paste top output of last cell\n",
    "\n",
    "df = pd.concat([over_target, under_target]).reset_index(drop=True)\n",
    "\n",
    "# add target to column to new 50/50 dataset\n",
    "\n",
    "df['target'] = df.trend_days > target_days\n",
    "df['target'] = df['target'].astype(int) # makes 1 or 0 for T or F\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(over_target.shape)\n",
    "print(under_target.shape)\n",
    "print(df.shape)\n",
    "print(\" \")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32104b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chose your features\n",
    "\n",
    "X = df[[\n",
    "    'category_e',\n",
    "    'publish_to_trend',\n",
    "    'publish_day_num',\n",
    "    'pt_views',\n",
    "    'pt_likes',\n",
    "    'pt_dislikes',\n",
    "    'pt_comments',\n",
    "    'likes_ratio',\n",
    "    'comments_ratio'\n",
    "    ]].to_numpy()\n",
    "\n",
    "y = df['trend_days'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "44c3d4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167238, 9)\n",
      "(167238,)\n"
     ]
    }
   ],
   "source": [
    "# if not scaling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ca760973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167238, 9)\n",
      "(167238,)\n"
     ]
    }
   ],
   "source": [
    "# if scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sclr  = scaler.fit(X)\n",
    "X_scaled = sclr.transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y,random_state=1)\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c9c6134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2e8d0b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-model function unscaled\n",
    "\n",
    "def test_model(model, data):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    reg = model.fit(X_train, y_train)\n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test, y_test)}\\n')\n",
    "    plt.show()   \n",
    "\n",
    "# bring in models\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "#from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "127a5a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression\n",
      "Train score: 5.059437280074963e-05\n",
      "Test Score: -5.56641482107878e-05\n",
      "\n",
      "Model: Lasso\n",
      "Train score: 2.7429440533466298e-05\n",
      "Test Score: -1.5695525985348624e-05\n",
      "\n",
      "Model: KNeighborsRegressor\n",
      "Train score: 0.2011082051076778\n",
      "Test Score: -0.19949517853188614\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.8551751092271346\n",
      "Test Score: -0.0318990141687272\n",
      "\n",
      "Model: ExtraTreesRegressor\n",
      "Train score: 1.0\n",
      "Test Score: -0.061304058667420724\n",
      "\n",
      "Model: AdaBoostRegressor\n",
      "Train score: -0.06700268423789812\n",
      "Test Score: -0.06837486979079666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unscaled run\n",
    "\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "\n",
    "test_model(LinearRegression(), data)\n",
    "test_model(Lasso(max_iter=2000),data)\n",
    "test_model(KNeighborsRegressor(), data)\n",
    "test_model(RandomForestRegressor(), data)\n",
    "test_model(ExtraTreesRegressor(), data)\n",
    "test_model(AdaBoostRegressor(), data)\n",
    "#test_model(SVR(C=1.0, epsilon=0.2), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1fc54232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-model function scaled\n",
    "\n",
    "def test_model(model, data):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data_scaled\n",
    "    reg = model.fit(X_train_scaled, y_train)\n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test_scaled, y_test)}\\n')\n",
    "    plt.show()   \n",
    "\n",
    "# bring in models\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "#from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "37e21321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression\n",
      "Train score: 0.8568744710265116\n",
      "Test Score: 0.8604595082670738\n",
      "\n",
      "Model: Lasso\n",
      "Train score: 0.7235502051012375\n",
      "Test Score: 0.7242328687840727\n",
      "\n",
      "Model: KNeighborsRegressor\n",
      "Train score: 0.9402469985181723\n",
      "Test Score: 0.9078926652327605\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9909634756642327\n",
      "Test Score: 0.9352095191760438\n",
      "\n",
      "Model: ExtraTreesRegressor\n",
      "Train score: 1.0\n",
      "Test Score: 0.9355564579948066\n",
      "\n",
      "Model: AdaBoostRegressor\n",
      "Train score: 0.8640601695168255\n",
      "Test Score: 0.8608282322321918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scaled run\n",
    "\n",
    "data_scaled = [X_train_scaled, X_test_scaled, y_train, y_test]\n",
    "\n",
    "test_model(LinearRegression(), data_scaled)\n",
    "test_model(Lasso(max_iter=2000),data_scaled)\n",
    "test_model(KNeighborsRegressor(), data_scaled)\n",
    "test_model(RandomForestRegressor(), data_scaled)\n",
    "test_model(ExtraTreesRegressor(), data_scaled)\n",
    "test_model(AdaBoostRegressor(), data_scaled)\n",
    "#test_model(SVR(C=1.0, epsilon=0.2), data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd948b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
